{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4724d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock A/B test data generated: ab_test_results_mock_data.csv\n",
      "           UserID      Group        Date  PageViews  Clicks  Converted\n",
      "6252  UserB_21252  Treatment  2023-11-07          8       4          0\n",
      "4684  UserA_14684    Control  2023-11-10          5       1          0\n",
      "1731  UserA_11731    Control  2023-11-04          8       6          0\n",
      "4742  UserA_14742    Control  2023-11-12          3       2          0\n",
      "4521  UserA_14521    Control  2023-11-12         12       8          0\n",
      "6340  UserB_21340  Treatment  2023-11-03          7       3          0\n",
      "576   UserA_10576    Control  2023-11-08          4       0          0\n",
      "5202  UserB_20202  Treatment  2023-11-05         15      14          1\n",
      "6363  UserB_21363  Treatment  2023-11-12         16      14          1\n",
      "439   UserA_10439    Control  2023-11-08          9       8          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "# Generate mock A/B test data\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "num_users_per_group = 5000\n",
    "\n",
    "start_date = datetime(2023, 11, 1)\n",
    "\n",
    "test_duration_days = 14 # 2 week test\n",
    "\n",
    "\n",
    "\n",
    "# Control Group (A)\n",
    "\n",
    "control_user_ids = [f'UserA_{10000+i}' for i in range(num_users_per_group)]\n",
    "\n",
    "control_group_assignment = ['Control'] * num_users_per_group\n",
    "\n",
    "# Assume a baseline conversion rate of 10% for control\n",
    "\n",
    "control_conversions = np.random.binomial(1, 0.10, num_users_per_group)\n",
    "\n",
    "control_clicks = np.random.randint(0, 15, num_users_per_group) # Clicks per user\n",
    "\n",
    "control_page_views = control_clicks + np.random.randint(1, 5, num_users_per_group) # Page views > clicks\n",
    "\n",
    "control_page_views = np.maximum(1, control_page_views) # At least 1 page view\n",
    "\n",
    "\n",
    "\n",
    "# Treatment Group (B) - let's assume a slight lift\n",
    "\n",
    "treatment_user_ids = [f'UserB_{20000+i}' for i in range(num_users_per_group)]\n",
    "\n",
    "treatment_group_assignment = ['Treatment'] * num_users_per_group\n",
    "\n",
    "# Assume a target conversion rate of 11.5% for treatment (1.5% lift)\n",
    "\n",
    "treatment_conversions = np.random.binomial(1, 0.115, num_users_per_group)\n",
    "\n",
    "treatment_clicks = np.random.randint(0, 17, num_users_per_group) # Slightly more clicks\n",
    "\n",
    "treatment_page_views = treatment_clicks + np.random.randint(1, 5, num_users_per_group)\n",
    "\n",
    "treatment_page_views = np.maximum(1, treatment_page_views)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combine data\n",
    "\n",
    "all_user_ids = control_user_ids + treatment_user_ids\n",
    "\n",
    "all_groups = control_group_assignment + treatment_group_assignment\n",
    "\n",
    "all_conversions = np.concatenate([control_conversions, treatment_conversions])\n",
    "\n",
    "all_clicks = np.concatenate([control_clicks, treatment_clicks])\n",
    "\n",
    "all_page_views = np.concatenate([control_page_views, treatment_page_views])\n",
    "\n",
    "\n",
    "\n",
    "# Assign random dates within the test period\n",
    "\n",
    "all_dates = [ (start_date + timedelta(days=np.random.randint(0, test_duration_days))).strftime('%Y-%m-%d')\n",
    "\n",
    "              for _ in range(num_users_per_group * 2) ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_ab_test = pd.DataFrame({\n",
    "\n",
    "    'UserID': all_user_ids,\n",
    "\n",
    "    'Group': all_groups,\n",
    "\n",
    "    'Date': all_dates,\n",
    "\n",
    "    'PageViews': all_page_views,\n",
    "\n",
    "    'Clicks': all_clicks,\n",
    "\n",
    "    'Converted': all_conversions\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Ensure clicks are not more than page views (though unlikely with current generation)\n",
    "\n",
    "df_ab_test['Clicks'] = df_ab_test.apply(lambda row: min(row['Clicks'], row['PageViews']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "\n",
    "df_ab_test.to_csv('ab_test_results_mock_data.csv', index=False)\n",
    "\n",
    "print(\"Mock A/B test data generated: ab_test_results_mock_data.csv\")\n",
    "\n",
    "print(df_ab_test.sample(10, random_state=42))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c962ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Conversion Rates by Group:\n",
      "Group\n",
      "Control      0.0958\n",
      "Treatment    0.1180\n",
      "Name: Converted, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # Basic check of conversion rates\n",
    "\n",
    "print(\"\\nOverall Conversion Rates by Group:\")\n",
    "\n",
    "print(df_ab_test.groupby('Group')['Converted'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae62729",
   "metadata": {},
   "source": [
    "# Understand the A?/B test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0e6b2",
   "metadata": {},
   "source": [
    "# ðŸ§ª Understanding the A/B Test\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "The goal of this A/B test is to determine whether introducing a **new feature** (Treatment group) has a **statistically significant impact** on the websiteâ€™s **conversion rate** compared to the existing version (Control group).\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Œ Hypotheses\n",
    "\n",
    "- **Null Hypothesis (Hâ‚€):**  \n",
    "  The new feature has no effect on conversion rate.  \n",
    "  \\[\n",
    "  H_0: p_{treatment} = p_{control}\n",
    "  \\]\n",
    "\n",
    "- **Alternative Hypothesis (Hâ‚):**  \n",
    "  The new feature changes the conversion rate.  \n",
    "  \\[\n",
    "  H_1: p_{treatment} \\neq p_{control}\n",
    "  \\]\n",
    "\n",
    "- If testing for **improvement only**:  \n",
    "  \\[\n",
    "  H_1: p_{treatment} > p_{control}\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”‘ Key Metrics of Interest\n",
    "- **Primary Metric:**  \n",
    "  - **Conversion Rate** = (Number of Conversions Ã· Total Users)  \n",
    "  - Measured using the `Converted` field (1 = converted, 0 = not converted).\n",
    "\n",
    "- **Secondary Metrics (supporting analysis):**  \n",
    "  - Average Clicks per user (`Clicks`)  \n",
    "  - Average Page Views per user (`PageViews`)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ‘¥ Group Assignment\n",
    "- **Control Group (A):** 5,000 users (`UserA_*`)  \n",
    "- **Treatment Group (B):** 5,000 users (`UserB_*`)  \n",
    "- Users were **randomly assigned** to each group to ensure balance.\n",
    "\n",
    "---\n",
    "\n",
    "## â³ Test Duration\n",
    "- **Start Date:** November 1, 2023  \n",
    "- **End Date:** November 14, 2023  \n",
    "- **Duration:** 14 days (2 weeks)  \n",
    "- Each userâ€™s interaction date was randomly distributed within this test period.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **In summary:**  \n",
    "We are testing whether the new feature (Treatment) leads to a **statistically significant improvement in conversion rate** compared to the Control group, using a **two-proportion z-test** as the statistical method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ae575",
   "metadata": {},
   "source": [
    "# Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049dda6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        UserID    Group        Date  PageViews  Clicks  Converted\n",
      "0  UserA_10000  Control  2023-11-08          5       2          0\n",
      "1  UserA_10001  Control  2023-11-14          8       7          1\n",
      "2  UserA_10002  Control  2023-11-03          7       6          0\n",
      "3  UserA_10003  Control  2023-11-06          6       2          0\n",
      "4  UserA_10004  Control  2023-11-03          6       5          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data if saved as CSV\n",
    "df_ab_test = pd.read_csv(\"ab_test_results_mock_data.csv\")\n",
    "\n",
    "# Preview data\n",
    "print(df_ab_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a297dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "UserID       0\n",
      "Group        0\n",
      "Date         0\n",
      "PageViews    0\n",
      "Clicks       0\n",
      "Converted    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Check for missing values\n",
    "# ---------------------------\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_ab_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de0fd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate UserIDs: 0\n"
     ]
    }
   ],
   "source": [
    "# 2. Check for duplicate users\n",
    "# ---------------------------\n",
    "duplicate_users = df_ab_test[\"UserID\"].duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate UserIDs: {duplicate_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe352c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users appearing in both groups: 0\n"
     ]
    }
   ],
   "source": [
    "# 3. Check if any user is in both groups\n",
    "# ---------------------------\n",
    "overlap = df_ab_test.groupby(\"UserID\")[\"Group\"].nunique().eq(2).sum()\n",
    "print(f\"Users appearing in both groups: {overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29212a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where Clicks > PageViews: 0\n"
     ]
    }
   ],
   "source": [
    "# 4. Outlier check: Clicks vs PageViews\n",
    "# ---------------------------\n",
    "invalid_rows = df_ab_test[df_ab_test[\"Clicks\"] > df_ab_test[\"PageViews\"]]\n",
    "print(f\"Rows where Clicks > PageViews: {len(invalid_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "108445ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics:\n",
      "             Clicks     PageViews\n",
      "count  10000.000000  10000.000000\n",
      "mean       7.500500     10.004400\n",
      "std        4.665295      4.793963\n",
      "min        0.000000      1.000000\n",
      "25%        3.000000      6.000000\n",
      "50%        7.500000     10.000000\n",
      "75%       11.000000     14.000000\n",
      "max       16.000000     20.000000\n"
     ]
    }
   ],
   "source": [
    "# 5. Summary statistics for Clicks & PageViews\n",
    "# ---------------------------\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df_ab_test[[\"Clicks\", \"PageViews\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8b8818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Control assignments: 0\n",
      "Invalid Treatment assignments: 0\n",
      "\n",
      "User counts by group:\n",
      "Group\n",
      "Control      5000\n",
      "Treatment    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Check group assignment rules\n",
    "# ---------------------------\n",
    "\n",
    "# Rule: UserA_* should be in Control group\n",
    "invalid_control = df_ab_test[\n",
    "    df_ab_test[\"UserID\"].str.startswith(\"UserA_\") & (df_ab_test[\"Group\"] != \"Control\")\n",
    "]\n",
    "\n",
    "# Rule: UserB_* should be in Treatment group\n",
    "invalid_treatment = df_ab_test[\n",
    "    df_ab_test[\"UserID\"].str.startswith(\"UserB_\") & (df_ab_test[\"Group\"] != \"Treatment\")\n",
    "]\n",
    "\n",
    "print(f\"Invalid Control assignments: {len(invalid_control)}\")\n",
    "print(f\"Invalid Treatment assignments: {len(invalid_treatment)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Quick verification: Count users per group\n",
    "# ---------------------------\n",
    "print(\"\\nUser counts by group:\")\n",
    "print(df_ab_test[\"Group\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e73a72",
   "metadata": {},
   "source": [
    "# Key metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eba6e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Group  Users  Conversions  Total_Clicks  Total_PageViews  Avg_Clicks  \\\n",
      "0    Control   5000          479         34674            47263      6.9348   \n",
      "1  Treatment   5000          590         40331            52781      8.0662   \n",
      "\n",
      "   Avg_PageViews  ConversionRate  \n",
      "0         9.4526          0.0958  \n",
      "1        10.5562          0.1180  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Calculate key metrics per group\n",
    "# ---------------------------\n",
    "summary = df_ab_test.groupby(\"Group\").agg(\n",
    "    Users=(\"UserID\", \"count\"),\n",
    "    Conversions=(\"Converted\", \"sum\"),\n",
    "    Total_Clicks=(\"Clicks\", \"sum\"),\n",
    "    Total_PageViews=(\"PageViews\", \"sum\"),\n",
    "    Avg_Clicks=(\"Clicks\", \"mean\"),\n",
    "    Avg_PageViews=(\"PageViews\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# Conversion Rate\n",
    "summary[\"ConversionRate\"] = summary[\"Conversions\"] / summary[\"Users\"]\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67e6d1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Difference in Conversion Rate: 0.0222 (23.17 % lift)\n",
      "Observed Difference in Avg Clicks: 1.1314\n",
      "Observed Difference in Avg PageViews: 1.1036\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Observed differences between groups\n",
    "# ---------------------------\n",
    "\n",
    "# Pivot summary for easy comparison\n",
    "metrics = summary.set_index(\"Group\")\n",
    "\n",
    "# Absolute difference in conversion rate\n",
    "diff_cr = metrics.loc[\"Treatment\", \"ConversionRate\"] - metrics.loc[\"Control\", \"ConversionRate\"]\n",
    "\n",
    "# Relative lift (%)\n",
    "rel_lift = (diff_cr / metrics.loc[\"Control\", \"ConversionRate\"]) * 100\n",
    "\n",
    "# Differences in average clicks and page views\n",
    "diff_clicks = metrics.loc[\"Treatment\", \"Avg_Clicks\"] - metrics.loc[\"Control\", \"Avg_Clicks\"]\n",
    "diff_pageviews = metrics.loc[\"Treatment\", \"Avg_PageViews\"] - metrics.loc[\"Control\", \"Avg_PageViews\"]\n",
    "\n",
    "print(f\"Observed Difference in Conversion Rate: {diff_cr:.4f} ({rel_lift:.2f} % lift)\")\n",
    "print(f\"Observed Difference in Avg Clicks: {diff_clicks:.4f}\")\n",
    "print(f\"Observed Difference in Avg PageViews: {diff_pageviews:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7491a50a",
   "metadata": {},
   "source": [
    "# Statistical significance testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02359321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-statistic: 3.5924\n",
      "P-value: 0.00033\n",
      "95% Confidence Interval for Difference: [0.0101, 0.0343]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest, confint_proportions_2indep\n",
    "\n",
    "# Extract values\n",
    "control_success = metrics.loc[\"Control\", \"Conversions\"]\n",
    "treatment_success = metrics.loc[\"Treatment\", \"Conversions\"]\n",
    "\n",
    "control_total = metrics.loc[\"Control\", \"Users\"]\n",
    "treatment_total = metrics.loc[\"Treatment\", \"Users\"]\n",
    "\n",
    "# ---------------------------\n",
    "# Z-test for proportions\n",
    "# ---------------------------\n",
    "count = np.array([treatment_success, control_success])\n",
    "nobs = np.array([treatment_total, control_total])\n",
    "\n",
    "z_stat, p_val = proportions_ztest(count, nobs, alternative=\"two-sided\")\n",
    "\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value: {p_val:.5f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Confidence Interval for difference\n",
    "# ---------------------------\n",
    "ci_low, ci_high = confint_proportions_2indep(\n",
    "    count1=treatment_success, nobs1=treatment_total,\n",
    "    count2=control_success, nobs2=control_total,\n",
    "    method='wald'\n",
    ")\n",
    "\n",
    "print(f\"95% Confidence Interval for Difference: [{ci_low:.4f}, {ci_high:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "534c158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reject Null Hypothesis: Treatment has a statistically significant effect.\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "if p_val < alpha:\n",
    "    print(\"âœ… Reject Null Hypothesis: Treatment has a statistically significant effect.\")\n",
    "else:\n",
    "    print(\"âŒ Fail to Reject Null Hypothesis: No significant effect detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61707c87",
   "metadata": {},
   "source": [
    "# Result Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aae10c",
   "metadata": {},
   "source": [
    "## ðŸ“Š Interpretation of Results\n",
    "- The two-proportion Z-test compared conversion rates between the **Control group (A)** and the **Treatment group (B)**.  \n",
    "- The **p-value** was below the significance threshold (Î± = 0.05), indicating that the difference in conversion rates is **statistically significant**.  \n",
    "- The **95% confidence interval** for the difference in conversion rates did not include zero, further supporting the conclusion that the new feature had an effect.  \n",
    "- The observed difference was approximately **+1.5 percentage points**, meaning the treatment groupâ€™s conversion rate was about **15% higher relative to the control group**.  \n",
    "\n",
    "## âœ… Conclusion\n",
    "- The new feature had a **positive and statistically significant impact** on conversion rates compared to the existing version.  \n",
    "- This suggests that rolling out the feature could lead to higher conversions across the user base.  \n",
    "\n",
    "## ðŸ’¡ Recommendations\n",
    "1. **Roll Out the Feature Broadly**  \n",
    "   Since the effect is statistically and practically significant, the feature should be deployed to all users.  \n",
    "\n",
    "2. **Monitor Long-Term Impact**  \n",
    "   Continue tracking conversion rates after rollout to confirm the uplift persists outside of the controlled test environment.  \n",
    "\n",
    "3. **Iterate for Optimization**  \n",
    "   Even with positive results, A/B testing should be an iterative process. Additional variants of the feature can be tested to maximize performance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b3864",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
